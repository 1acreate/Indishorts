<!doctype html>
<html lang="hi">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Script → Cinematic Short (Mobile)</title>
<style>
  :root{--bg:#071027}
  body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial;background:linear-gradient(180deg,#020617,#071029);color:#e6eef8}
  .wrap{max-width:900px;margin:12px auto;padding:12px}
  h1{font-size:18px;margin:0 0 8px}
  .card{background:rgba(255,255,255,0.03);padding:12px;border-radius:12px}
  textarea{width:100%;height:120px;border-radius:10px;padding:8px;background:#05122a;color:#e6eef8;border:1px solid rgba(255,255,255,0.03)}
  input,select,button{width:100%;padding:10px;border-radius:10px;border:0;background:#ff6a00;color:#fff;font-weight:700}
  .row{display:grid;grid-template-columns:1fr 1fr;gap:8px;margin-top:8px}
  canvas{width:100%;height:auto;border-radius:10px;background:#000;margin-top:10px}
  .muted{opacity:0.85;font-size:13px;margin-top:8px}
  @media(max-width:640px){ .row{grid-template-columns:1fr} button{width:49%} }
</style>
</head>
<body>
  <div class="wrap">
    <h1>Script → Cinematic Short (Mobile)</h1>
    <div class="card">
      <label class="muted">Script (Hindi) — short lines work best (5–60s)</label>
      <textarea id="script">Yahan apna Hindi script likho. Chhote aur punchy sentences best hote hain.</textarea>

      <div class="row">
        <div>
          <label class="muted">Duration (seconds)</label>
          <input id="duration" type="number" value="25" min="5" max="60" />
        </div>
        <div>
          <label class="muted">Watermark</label>
          <input id="watermark" value="@YourChannel" />
        </div>
      </div>

      <div style="display:flex;gap:8px;margin-top:10px;align-items:center">
        <button id="startBtn">Start Capture & Generate</button>
        <a id="downloadLink" style="display:inline-block;width:48%;text-align:center;padding:10px;border-radius:10px;background:#222;color:#fff;text-decoration:none;margin-left:8px" download="short.webm">Download</a>
      </div>

      <canvas id="stage" width="720" height="1280"></canvas>
      <div class="muted" id="status">Status: idle — Press <strong>Start Capture & Generate</strong>. Allow screen + audio when prompted.</div>
      <div class="muted">Note: On prompt, choose to share the browser tab/screen and enable audio capture so that the voice is recorded into the video.</div>
    </div>
  </div>

<script>
const canvas = document.getElementById('stage');
const ctx = canvas.getContext('2d');
const startBtn = document.getElementById('startBtn');
const downloadLink = document.getElementById('downloadLink');
const statusEl = document.getElementById('status');
const scriptEl = document.getElementById('script');
const durationEl = document.getElementById('duration');
const watermarkEl = document.getElementById('watermark');

let recorder, recordedChunks = [];

// Simple cinematic draw
function drawFrame(progress, text, watermark){
  const w = canvas.width, h = canvas.height;
  // animated gradient
  const g = ctx.createLinearGradient(0,0,w,h);
  g.addColorStop(0, `rgba(${40 + Math.floor(30*Math.sin(progress*2))}, 20, 50, 1)`);
  g.addColorStop(1, `rgba(8, 30, ${80 + Math.floor(50*Math.cos(progress*1.2))}, 1)`);
  ctx.fillStyle = g;
  ctx.fillRect(0,0,w,h);

  // moving flare
  const flareX = (Math.sin(progress*Math.PI*2)+1)/2 * w;
  ctx.globalAlpha = 0.12;
  ctx.beginPath(); ctx.ellipse(flareX, h*0.22, w*0.6, h*0.18, 0,0,Math.PI*2); ctx.fillStyle='rgba(255,150,90,0.9)'; ctx.fill(); ctx.globalAlpha=1;

  // cinematic bars
  ctx.fillStyle = '#000'; ctx.fillRect(0,0,w,96); ctx.fillRect(0,h-96,w,96);

  // main text
  ctx.fillStyle = '#fff'; ctx.textAlign = 'center'; ctx.font = 'bold 56px system-ui';
  wrapText(ctx, text, w/2, h/2 - 30, w - 160, 56);

  // watermark
  ctx.font = '600 28px system-ui'; ctx.fillStyle = 'rgba(255,255,255,0.18)'; ctx.textAlign='right';
  ctx.fillText(watermark, w - 34, h - 50);

  // vignette
  const rad = ctx.createRadialGradient(w/2,h/2,h*0.1,w/2,h/2,Math.max(w,h));
  rad.addColorStop(0,'rgba(0,0,0,0)'); rad.addColorStop(1,'rgba(0,0,0,0.45)');
  ctx.fillStyle = rad; ctx.fillRect(0,0,w,h);
}

function wrapText(ctx, text, x, y, maxWidth, lineHeight){
  const words = text.split(' ');
  let line = '', ty = y;
  for(let n=0;n<words.length;n++){
    const test = line + words[n] + ' ';
    const metrics = ctx.measureText(test);
    if(metrics.width > maxWidth && n>0){
      ctx.fillText(line, x, ty);
      line = words[n] + ' ';
      ty += lineHeight;
    } else line = test;
  }
  ctx.fillText(line, x, ty);
}

// small background ambience (not required to be captured, but helps preview)
let bgAudioCtx = null;
function startBgMusic(){
  try{
    bgAudioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const o = bgAudioCtx.createOscillator();
    const g = bgAudioCtx.createGain();
    o.type='sine'; o.frequency.value=120;
    g.gain.value = 0.02;
    o.connect(g); g.connect(bgAudioCtx.destination);
    o.start();
    return {o,g};
  } catch(e){ return null; }
}

function stopBgMusic(node){
  try{ if(node && node.o) node.o.stop(); if(bgAudioCtx) bgAudioCtx.close(); bgAudioCtx = null; } catch(e){}
}

// main: request screen capture (with audio) then record while animating + speaking
startBtn.addEventListener('click', async ()=>{
  startBtn.disabled = true;
  downloadLink.removeAttribute('href'); downloadLink.textContent = 'Download';
  recordedChunks = [];
  updateStatus('Requesting screen capture — allow screen + audio in the prompt.');

  let displayStream = null;
  try{
    // ask user to share screen/tab with system audio — many Android Chrome versions support this
    displayStream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: true });
  } catch(err){
    alert('Screen capture not allowed or not supported on this browser. Try Chrome on Android with "Share audio" enabled.');
    updateStatus('Screen capture failed. See alert.');
    startBtn.disabled = false;
    return;
  }

  updateStatus('Screen capture started. Preparing recording...');

  // Prepare recorder from display stream (this will include system/tab audio if allowed)
  const mime = MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus') ? 'video/webm;codecs=vp9,opus' : 'video/webm';
  try{
    recorder = new MediaRecorder(displayStream, { mimeType: mime });
  } catch(e){
    recorder = new MediaRecorder(displayStream);
  }

  recorder.ondataavailable = (e) => { if(e.data && e.data.size) recordedChunks.push(e.data); };
  recorder.onstop = () => {
    const blob = new Blob(recordedChunks, { type: recordedChunks[0]?.type || 'video/webm' });
    const url = URL.createObjectURL(blob);
    downloadLink.href = url;
    downloadLink.download = 'short.webm';
    downloadLink.textContent = 'Download Video';
    updateStatus('Recording finished. Click Download.');
    // stop all tracks from displayStream
    try{ displayStream.getTracks().forEach(t=>t.stop()); } catch(e){}
    startBtn.disabled = false;
  };

  recorder.start(200); // gather data chunks
  updateStatus('Recording... Playing voice and rendering scene. Wait until finished.');

  // start lightweight background music locally (helps preview; system audio capture may or may not include it)
  const bgNode = startBgMusic();

  // speak script using Web Speech (Hindi)
  const script = scriptEl.value.trim() || 'Yeh ek quick demo video hai. Use short lines for better results.';
  const duration = Math.max(5, Math.min(60, Number(durationEl.value) || 25));
  const watermark = watermarkEl.value || '@YourChannel';

  // split script into parts for progressive display
  const words = script.split(/\s+/);
  const chunksCount = Math.max(1, Math.ceil(duration / 5));
  const chunkSize = Math.ceil(words.length / chunksCount);
  const chunks = [];
  for(let i=0;i<chunksCount;i++) chunks.push(words.slice(i*chunkSize, (i+1)*chunkSize).join(' '));

  // choose Hindi female voice if available
  let chosenVoice = null;
  const voices = speechSynthesis.getVoices();
  if(voices && voices.length){
    chosenVoice = voices.find(v => /hi|hindi/i.test(v.lang) && /female|woman|female|f/i.test(v.name)) ||
                  voices.find(v => /hi|hindi/i.test(v.lang)) ||
                  voices.find(v => /female|woman|female|f/i.test(v.name)) ||
                  voices[0];
  }

  // animate & speak each chunk
  const fps = 30;
  const totalFrames = Math.round(duration * fps);

  for(let i=0;i<totalFrames;i++){
    const progress = i / totalFrames;
    // decide which chunk to show based on progress
    const chunkIndex = Math.floor(progress * chunks.length);
    drawFrame(progress, chunks[chunkIndex] || script, watermark);
    await sleep(Math.round(1000 / fps));
    // speak at the start of each chunk (non-blocking)
    const shouldSpeak = (i % Math.round(fps * (duration / chunks.length)) === 0);
    if(shouldSpeak && chunks[chunkIndex] && speechSynthesis){
      const msg = new SpeechSynthesisUtterance(chunks[chunkIndex]);
      msg.lang = 'hi-IN';
      if(chosenVoice) msg.voice = chosenVoice;
      msg.rate = 1.0; msg.pitch = 1.0;
      try { speechSynthesis.speak(msg); } catch(e) { console.warn('TTS speak error', e); }
    }
  }

  // small pause to let TTS finish speaking if display capture is including audio
  updateStatus('Finalizing... waiting for audio to finish.');
  await sleep(900);

  // stop recorder
  try{ recorder.stop(); } catch(e){ console.warn('Stop recorder err', e); }

  // cleanup bg music
  stopBgMusic(bgNode);
});

function updateStatus(t){ statusEl.textContent = 'Status: ' + t; }
function sleep(ms){ return new Promise(res => setTimeout(res, ms)); }

</script>
</body>
</html>